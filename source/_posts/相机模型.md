---
title: 相机模型
mathjax: true
date: 2021-03-06 18:41:09
tags:
- SLAM
categories: SLAM
---
针孔相机模型，若干种坐标系的转换方法
<!-- more -->

## 几个坐标系

针孔相机模型就是小孔成像模型，通过针孔后目标在成像平面上形成了一个倒立（通常缩小）的像。

借用十四讲里的图：
<img src='model.png' width=600 title='针孔相机模型'>

上图描述了相机坐标系中的$P$点经转换后在图像坐标系$x'O'y'$成像的过程。

需要注意，上图里$x'O'y'$图像坐标系的原点$O'$是成像平面与过光心直线的交点，下面要说的像素坐标系与图像坐标系在同一个平面上，但标度和原点不同，此图并没有画出。

<img src='ouv.png' width=600 title='像素坐标系'>

上图为从坐在相机里内向外看的视角，**像素坐标系**的原点在图像左上角，$u$轴向右，$v$轴向下；**图像坐标系**原点在过光心直线与平面交点，$x$轴向右，$y$轴向下。

顺便提及，**相机坐标系**的原点设置在光心处，同向看去，$Z$轴朝外，$X$轴向右，$Y$轴向下。（另外俩坐标系没有Z轴）

-----

## 坐标转换

相机坐标系$(X,Y,Z)$至图像坐标系$(x,y)$

$$ \frac{Z}{f}=\frac{X}{x}=\frac{Y}{y}$$

$f$为相机焦距

图像坐标系$(x,y)$至像素坐标系$(u,v)$

$$ \left\{
    \begin{array}{lr}
    u = \alpha x + c_x & \\
    v =  \beta y + c_y& \\
    \end{array}

    \right. $$

$\alpha 和 \beta$是像素每米的转换比例，$c_x 和c_y$是两个坐标系原点的平移距离

再看一次

<img src='ouv.png' width=600 title='像素坐标系'>

由以上两个转换推出相机坐标系$(X,Y,Z)$至像素坐标系$(u,v)$

$$ \left\{
    \begin{array}{lr}
    u = f_x \frac{X}{Z} + c_x & \\
    v =  f_y \frac{Y}{Z} + c_y& \\
    \end{array}

    \right. $$

$$f_x = \alpha f, \quad f_y =\beta f$$

使用*齐次坐标*可以将上述表达变为矩阵形式，以及再加上相机坐标系到世界坐标系的转换

$$
\left[
    \begin{array}{lr}
    u\\
    v\\
    1\\
    \end{array}
    \right]
= \frac{1}{Z}
\left[
    \begin{array}{lr}
    f_x & 0 & c_x\\
    0 & f_y & c_y\\
    0 & 0 & 1\\
    \end{array}
    \right]

    \left[
    \begin{array}{lr}
    X\\
    Y\\
    Z\\
    \end{array}
    \right]
    =
    \frac{1}{Z} K P_c
    =
    \frac{1}{Z} K(RP_w + t)
    =
    \frac{1}{Z} KTP_w
$$

$K$矩阵为相机的**内参矩阵**，相机标定的对象就是它

十四讲中说习惯会把Z乘到左边

$$ Z P_{uv} = KTP_w$$

如果对相机坐标系下的坐标进行归一化处理，那么$Z=1$，$P_{uv}=KP_c$，即乘以内参矩阵就得到了像素坐标。

所以像素坐标也被认为是对**归一化平面**上的坐标进行量化测量的结果。

## 针孔模型与透镜

小孔成像是将一大堆光线挡住只让“一束光”穿过去成像，凸透镜是把所有光线聚集起来成像。

<img src='core2.gif' width=600 title='hole'>

知乎上图

https://www.zhihu.com/question/299247177

<img src='core.gif' width=600 title='2zero'>

小孔成像可以理解为透镜成像在孔径（光圈）趋近于零的极限情况。另外当孔径趋近于零时，景深趋近于无穷，成像的亮度也趋于零。

## 双目相机模型

通过同一物体在双目左右成像面的像素坐标，判断物体的距离

图源十四讲

<img src='stereo.png' width=600 title='2zero'>

根据相似关系

$$ \frac{z-f}{z} = \frac{b-u_L+u_R}{b}$$

注意$u_R$为负，进而推出$z$的大小

$$ z = \frac{fb}{d}, \quad d = u_L - u_R $$

双目模型估计深度的难点在于，如何精确的确定左右图像的像素对应关系，计算视差$d$的难度很大

双目相机由于$d$最小为1像素，所以$Z$的测量是有上限的


## 结构光与ToF相机

结构光相机向物体发射光斑或者条纹，再观察其形变来判断距离。

<img src='slc.jpg' width=600 title='structured light camera'>

ToF相机发射光线，测量返回光线的时间，来计算距离，Time of Flight。

<img src='tof.png' width=600 title='ToF camera'>

ToF相机和激光雷达有相似的地方，主动向外发射光线并用时间测距，不同的是激光雷达直接给出3D点云，ToF是给出一个RGB图像和一个深度图，不是一个3D的点云。